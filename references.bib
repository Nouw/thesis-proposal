%! Author = fabiodijkshoorn
%! Date = 05/02/2025
@misc{touvron2023llamaopenefficientfoundation,
    title={LLaMA: Open and Efficient Foundation Language Models},
    author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
    year={2023},
    eprint={2302.13971},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2302.13971},
}

@misc{brown2020languagemodelsfewshotlearners,
    title={Language Models are Few-Shot Learners},
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2005.14165},
}

@article{Kumar2024,
    title = {Large language models (LLMs): survey,  technical frameworks,  and future challenges},
    volume = {57},
    ISSN = {1573-7462},
    url = {http://dx.doi.org/10.1007/s10462-024-10888-y},
    DOI = {10.1007/s10462-024-10888-y},
    number = {10},
    journal = {Artificial Intelligence Review},
    publisher = {Springer Science and Business Media LLC},
    author = {Kumar,  Pranjal},
    year = {2024},
    month = aug
}

@article{chandra_exploring_2024,
    title = {Exploring the role of large language models in radiation emergency response},
    volume = {44},
    issn = {0952-4746},
    url = {https://dx.doi.org/10.1088/1361-6498/ad270c},
    doi = {10.1088/1361-6498/ad270c},
    abstract = {In recent times, the field of artificial intelligence (AI) has been transformed by the introduction of large language models (LLMs). These models, popularized by OpenAI’s GPT-3, have demonstrated the emergent capabilities of AI in comprehending and producing text resembling human language, which has helped them transform several industries. But its role has yet to be explored in the nuclear industry, specifically in managing radiation emergencies. The present work explores LLMs’ contextual awareness, natural language interaction, and their capacity to comprehend diverse queries in a radiation emergency response setting. In this study we identify different user types and their specific LLM use-cases in radiation emergencies. Their possible interactions with ChatGPT, a popular LLM, has also been simulated and preliminary results are presented. Drawing on the insights gained from this exercise and to address concerns of reliability and misinformation, this study advocates for expert guided and domain-specific LLMs trained on radiation safety protocols and historical data. This study aims to guide radiation emergency management practitioners and decision-makers in effectively incorporating LLMs into their decision support framework.},
    language = {en},
    number = {1},
    urldate = {2025-02-03},
    journal = {Journal of Radiological Protection},
    author = {Chandra, Anirudh and Chakraborty, Abinash},
    month = feb,
    year = {2024},
    note = {Publisher: IOP Publishing},
    keywords = {CBRN},
    pages = {011510},
    file = {IOP Full Text PDF:/Users/fabiodijkshoorn/Zotero/storage/4JPR9FWH/Chandra and Chakraborty - 2024 - Exploring the role of large language models in radiation emergency response.pdf:application/pdf},
}

@article{chang_llmscenario_2024,
    title = {{LLMScenario}: {Large} {Language} {Model} {Driven} {Scenario} {Generation}},
    shorttitle = {{LLMScenario}},
    doi = {10.1109/TSMC.2024.3392930},
    abstract = {Scenario engineering plays a vital role in various Industry 5.0 applications. In the field of autonomous driving systems, driving scenario data are important for the training and testing of critical modules. However, the corner scenario cases are usually rare and necessary to be extended. Existing methods cannot handle the interpretation and reasoning of the generation process well, which reduces the reliability and usability of the generated scenarios. With the rapid development of Foundation Models, especially the large language model (LLM), we can conduct scenario generation via more powerful tools. In this article, we propose LLMScenario, a novel LLM-driven scenario generation framework, which is composed of scenario prompt engineering, LLM scenario generation, and evaluation feedback tuning. The minimum scenario description specific to LLM is given by scenario analysis and ablation studies. We also appropriately design the score functions in terms of reality and rarity to evaluate the generated scenarios. The model performance is further enhanced through chain-of-thoughts and experiences. Different LLMs are also compared with our framework. Experimental results on naturalistic datasets demonstrate the effectiveness of LLMScenario, which can provide solid support for scenario engineering in Industry 5.0.},
    journal = {IEEE Transactions on Systems Man and Cybernetics Systems},
    author = {Chang, Cheng and Wang, Siqi and Zhang, Jiawei and Ge, Jingwei and Li, Li},
    month = may,
    year = {2024},
    keywords = {LLM},
    file = {Chang et al. - 2024 - LLMScenario Large Language Model Driven Scenario .pdf:/Users/fabiodijkshoorn/Zotero/storage/IWVQZQMR/Chang et al. - 2024 - LLMScenario Large Language Model Driven Scenario .pdf:application/pdf},
}

@phdthesis{iob_nuclear_2024,
    type = {laurea},
    title = {Nuclear {Security}: {A} {Natural} {Language} {Processing} {Generative} {Approach}},
    copyright = {cc\_by\_nc\_nd},
    shorttitle = {Nuclear {Security}},
    url = {https://webthesis.biblio.polito.it/30622/},
    abstract = {This thesis aims at investigating and evaluating the use of natural language gen-  erative models, specifically in the framework of generating training scenarios for  personnel working in critical infrastructures. Safety and security of an infrastruc-  ture containing radioactive material should be addressed with emergency planning,  which requires training scenarios for personnel involved. Such scenarios are tra-  ditionally developed by human experts, although this is a process that is subject  to several drawbacks. First of all, it requires a considerable amount of time for  producing a qualitative output. Second, it must deal with multiple repetitive steps,  thus leading to critical bottlenecks. Third, a final training scenario can at first  glance seem reproducible and on-point, but when it comes to put it in practice, its  plausibility might be insufficient. These aspects can ultimately lead to considerable  decrease in training quality, with severe consequences on overall safety and security.  With this in mind, the possibility of using generative methods in such pipeline has  been explored in this work. Generative methods employ the use of Large Language  Models (LLMs) to generate long and meaningful text from a simple user prompt.  These models leverage the power of Machine Learning (ML) techniques to infer  commonly occurring patterns in large training datasets.  The use of generative models in scenario development has the potential of stream-  lining the most tedious steps, thus improving quality and reliability for the final  result. Their use can be investigated with two methodologies in mind, where a fully  automated or a semi automated framework are both available solutions. In order  to assess the quality of the scenario, some key evaluation criteria were selected and  defined. After experimenting with multiple implementations and exploring existing  literature, a hierarchical framework using a Generative Pre-trained Transformer  (GPT) model was developed, with the aim of generating meaningful, complete  and usable scenarios. Multiple scenarios were extracted from several open source  examples found on internet archives, in particular from drills designed by interna-  tional agencies. Human experts were then asked to provide a score for each selected  evaluation criterion.  What has been observed after the scenario generation is that using a simple prompt,  with the bare model, lead to lack of important information, such as a detailed  timeline of the exercise. After providing a general structure, scenarios automatically  generated presented more adherence to scenarios designed by humans. When Chain  of Thought was used as a prompting strategy, outputs presented more detail and  adherence to the selected structure.  As a conclusion, the GPT model was able to generate meaningful scenarios, allowing  for flexibility in its implementation. When adopting the hierarchical architecture,  explicitly describing the context and limiting the working window helped the model  to perform better according to the evaluation criteria.},
    language = {it},
    urldate = {2025-02-03},
    school = {Politecnico di Torino},
    author = {Iob, Gabriele},
    month = mar,
    year = {2024},
    keywords = {CBRN, LLM},
    file = {Full Text PDF:/Users/fabiodijkshoorn/Zotero/storage/I8TA4SKA/Iob - 2024 - Nuclear Security A Natural Language Processing Generative Approach.pdf:application/pdf;Snapshot:/Users/fabiodijkshoorn/Zotero/storage/AQIFKL9N/30622.html:text/html},
}

@article{world2020personal,
    title={Personal protective equipment},
    author={{World Health Organization}},
    year={2020},
    publisher={World Health Organization}
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
    title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
    author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
    year={2023},
    eprint={2201.11903},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2201.11903},
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
    title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
    author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
    year={2021},
    eprint={2005.11401},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2005.11401},
}

@inproceedings{brasser2023scenario,
    title={Scenario dependent optimizing the protective ability of ppe against its physiological burden},
    author={Brasser, Ir Paul},
    booktitle={10 th European Conference on Protective Clothing},
    pages={44},
    year={2023}
}

@misc{grattafiori2024llama3herdmodels,
    title={The Llama 3 Herd of Models},
    author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
    year={2024},
    eprint={2407.21783},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2407.21783},
}
