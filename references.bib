%! Author = fabiodijkshoorn
%! Date = 05/02/2025
@misc{touvron2023llamaopenefficientfoundation,
    title={LLaMA: Open and Efficient Foundation Language Models},
    author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
    year={2023},
    eprint={2302.13971},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2302.13971},
}

@misc{brown2020languagemodelsfewshotlearners,
    title={Language Models are Few-Shot Learners},
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2005.14165},
}

@article{Kumar2024,
    title = {Large language models (LLMs): survey,  technical frameworks,  and future challenges},
    volume = {57},
    ISSN = {1573-7462},
    url = {http://dx.doi.org/10.1007/s10462-024-10888-y},
    DOI = {10.1007/s10462-024-10888-y},
    number = {10},
    journal = {Artificial Intelligence Review},
    publisher = {Springer Science and Business Media LLC},
    author = {Kumar,  Pranjal},
    year = {2024},
    month = aug
}

@article{chandra_exploring_2024,
    title = {Exploring the role of large language models in radiation emergency response},
    volume = {44},
    issn = {0952-4746},
    url = {https://dx.doi.org/10.1088/1361-6498/ad270c},
    doi = {10.1088/1361-6498/ad270c},
    abstract = {In recent times, the field of artificial intelligence (AI) has been transformed by the introduction of large language models (LLMs). These models, popularized by OpenAI’s GPT-3, have demonstrated the emergent capabilities of AI in comprehending and producing text resembling human language, which has helped them transform several industries. But its role has yet to be explored in the nuclear industry, specifically in managing radiation emergencies. The present work explores LLMs’ contextual awareness, natural language interaction, and their capacity to comprehend diverse queries in a radiation emergency response setting. In this study we identify different user types and their specific LLM use-cases in radiation emergencies. Their possible interactions with ChatGPT, a popular LLM, has also been simulated and preliminary results are presented. Drawing on the insights gained from this exercise and to address concerns of reliability and misinformation, this study advocates for expert guided and domain-specific LLMs trained on radiation safety protocols and historical data. This study aims to guide radiation emergency management practitioners and decision-makers in effectively incorporating LLMs into their decision support framework.},
    language = {en},
    number = {1},
    urldate = {2025-02-03},
    journal = {Journal of Radiological Protection},
    author = {Chandra, Anirudh and Chakraborty, Abinash},
    month = feb,
    year = {2024},
    note = {Publisher: IOP Publishing},
    keywords = {CBRN},
    pages = {011510},
    file = {IOP Full Text PDF:/Users/fabiodijkshoorn/Zotero/storage/4JPR9FWH/Chandra and Chakraborty - 2024 - Exploring the role of large language models in radiation emergency response.pdf:application/pdf},
}

@article{chang_llmscenario_2024,
    title = {{LLMScenario}: {Large} {Language} {Model} {Driven} {Scenario} {Generation}},
    shorttitle = {{LLMScenario}},
    doi = {10.1109/TSMC.2024.3392930},
    abstract = {Scenario engineering plays a vital role in various Industry 5.0 applications. In the field of autonomous driving systems, driving scenario data are important for the training and testing of critical modules. However, the corner scenario cases are usually rare and necessary to be extended. Existing methods cannot handle the interpretation and reasoning of the generation process well, which reduces the reliability and usability of the generated scenarios. With the rapid development of Foundation Models, especially the large language model (LLM), we can conduct scenario generation via more powerful tools. In this article, we propose LLMScenario, a novel LLM-driven scenario generation framework, which is composed of scenario prompt engineering, LLM scenario generation, and evaluation feedback tuning. The minimum scenario description specific to LLM is given by scenario analysis and ablation studies. We also appropriately design the score functions in terms of reality and rarity to evaluate the generated scenarios. The model performance is further enhanced through chain-of-thoughts and experiences. Different LLMs are also compared with our framework. Experimental results on naturalistic datasets demonstrate the effectiveness of LLMScenario, which can provide solid support for scenario engineering in Industry 5.0.},
    journal = {IEEE Transactions on Systems Man and Cybernetics Systems},
    author = {Chang, Cheng and Wang, Siqi and Zhang, Jiawei and Ge, Jingwei and Li, Li},
    month = may,
    year = {2024},
    keywords = {LLM},
    file = {Chang et al. - 2024 - LLMScenario Large Language Model Driven Scenario .pdf:/Users/fabiodijkshoorn/Zotero/storage/IWVQZQMR/Chang et al. - 2024 - LLMScenario Large Language Model Driven Scenario .pdf:application/pdf},
}

@phdthesis{iob_nuclear_2024,
    type = {laurea},
    title = {Nuclear {Security}: {A} {Natural} {Language} {Processing} {Generative} {Approach}},
    copyright = {cc\_by\_nc\_nd},
    shorttitle = {Nuclear {Security}},
    url = {https://webthesis.biblio.polito.it/30622/},
    abstract = {This thesis aims at investigating and evaluating the use of natural language gen-  erative models, specifically in the framework of generating training scenarios for  personnel working in critical infrastructures. Safety and security of an infrastruc-  ture containing radioactive material should be addressed with emergency planning,  which requires training scenarios for personnel involved. Such scenarios are tra-  ditionally developed by human experts, although this is a process that is subject  to several drawbacks. First of all, it requires a considerable amount of time for  producing a qualitative output. Second, it must deal with multiple repetitive steps,  thus leading to critical bottlenecks. Third, a final training scenario can at first  glance seem reproducible and on-point, but when it comes to put it in practice, its  plausibility might be insufficient. These aspects can ultimately lead to considerable  decrease in training quality, with severe consequences on overall safety and security.  With this in mind, the possibility of using generative methods in such pipeline has  been explored in this work. Generative methods employ the use of Large Language  Models (LLMs) to generate long and meaningful text from a simple user prompt.  These models leverage the power of Machine Learning (ML) techniques to infer  commonly occurring patterns in large training datasets.  The use of generative models in scenario development has the potential of stream-  lining the most tedious steps, thus improving quality and reliability for the final  result. Their use can be investigated with two methodologies in mind, where a fully  automated or a semi automated framework are both available solutions. In order  to assess the quality of the scenario, some key evaluation criteria were selected and  defined. After experimenting with multiple implementations and exploring existing  literature, a hierarchical framework using a Generative Pre-trained Transformer  (GPT) model was developed, with the aim of generating meaningful, complete  and usable scenarios. Multiple scenarios were extracted from several open source  examples found on internet archives, in particular from drills designed by interna-  tional agencies. Human experts were then asked to provide a score for each selected  evaluation criterion.  What has been observed after the scenario generation is that using a simple prompt,  with the bare model, lead to lack of important information, such as a detailed  timeline of the exercise. After providing a general structure, scenarios automatically  generated presented more adherence to scenarios designed by humans. When Chain  of Thought was used as a prompting strategy, outputs presented more detail and  adherence to the selected structure.  As a conclusion, the GPT model was able to generate meaningful scenarios, allowing  for flexibility in its implementation. When adopting the hierarchical architecture,  explicitly describing the context and limiting the working window helped the model  to perform better according to the evaluation criteria.},
    language = {it},
    urldate = {2025-02-03},
    school = {Politecnico di Torino},
    author = {Iob, Gabriele},
    month = mar,
    year = {2024},
    keywords = {CBRN, LLM},
    file = {Full Text PDF:/Users/fabiodijkshoorn/Zotero/storage/I8TA4SKA/Iob - 2024 - Nuclear Security A Natural Language Processing Generative Approach.pdf:application/pdf;Snapshot:/Users/fabiodijkshoorn/Zotero/storage/AQIFKL9N/30622.html:text/html},
}

@article{world2020personal,
    title={Personal protective equipment},
    author={{World Health Organization}},
    year={2020},
    publisher={World Health Organization}
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
    title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
    author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
    year={2023},
    eprint={2201.11903},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2201.11903},
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
    title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
    author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
    year={2021},
    eprint={2005.11401},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2005.11401},
}
